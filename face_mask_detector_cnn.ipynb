{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GadljuU7-oVV"
   },
   "source": [
    "# Google drive setup\n",
    "* Uses your google account's google drive to store dataset\n",
    "* Make sure to create a folder \"COMP-6721\" in the root of your google drive before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMJUTDPsshHz",
    "outputId": "6b25a1cd-7eb4-4345-9022-c0ed34225ac5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "os.chdir(\"drive/My Drive/COMP-6721\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6Xwq10x_B7d"
   },
   "source": [
    "# Download the dataset\n",
    "* Downloads the face mask dataset to your drive and unzips it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLq9jaWwm7fU",
    "outputId": "d74179eb-1afe-4e56-a36d-cd437d113b9a"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download dataset\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "# from google.colab import drive\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "dirpath = Path('data/dataset')\n",
    "if dirpath.exists() and dirpath.is_dir():\n",
    "    shutil.rmtree(dirpath)\n",
    "os.makedirs('data/dataset')\n",
    "datasetPath = Path('data/dataset/dataset.zip')\n",
    "gdd.download_file_from_google_drive(file_id='1tu9PmDx5mPCw1O-RTHLAzd25BGknsADQ',\n",
    "                                    dest_path=str(datasetPath),\n",
    "                                    unzip=True)\n",
    "# delete zip file\n",
    "datasetPath.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the pickle\n",
    "If the dataset is already available locally, skip the previous cell and run the one below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preparing pickle\n",
    "\"\"\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "datasetPath = Path('data/dataset')\n",
    "maskPath = datasetPath/'with_mask'\n",
    "nonMaskPath = datasetPath/'without_mask'\n",
    "randomPath = datasetPath/'random'\n",
    "maskDF = pd.DataFrame()\n",
    "\n",
    "for imgPath in tqdm(list(maskPath.iterdir()), desc='with_mask'):\n",
    "    maskDF = maskDF.append({\n",
    "        'image': str(imgPath),\n",
    "        'mask': 1\n",
    "    }, ignore_index=True)\n",
    "\n",
    "for imgPath in tqdm(list(nonMaskPath.iterdir()), desc='without_mask'):\n",
    "    maskDF = maskDF.append({\n",
    "        'image': str(imgPath),\n",
    "        'mask': 0\n",
    "    }, ignore_index=True)\n",
    "\n",
    "for imgPath in tqdm(list(randomPath.iterdir()), desc='random_images'):\n",
    "    maskDF = maskDF.append({\n",
    "        'image': str(imgPath),\n",
    "        'mask': 2\n",
    "    }, ignore_index=True)\n",
    "\n",
    "dfName = 'data/dataset/dataset.pickle'\n",
    "print(f'Saving Dataframe to: {dfName}')\n",
    "maskDF.to_pickle(dfName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzN0YEDDAE40"
   },
   "source": [
    "# The Dataset class\n",
    "* Loads the dataset as PIL\n",
    "* Resizes images to 32x32\n",
    "* Convert image to tensor\n",
    "* Normalizes images to have values in the range of 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSkrJ9l4oKNK"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The DataSet class\n",
    "\"\"\"\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import long, tensor\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "\n",
    "class MaskDetectionDataset(Dataset):\n",
    "    def __init__(self, dataFrame):\n",
    "        self.dataFrame = dataFrame\n",
    "        \n",
    "        self.transformations = Compose([\n",
    "            Resize((32, 32)),\n",
    "            ToTensor(),\n",
    "            Normalize((0.5667, 0.5198, 0.4955),(0.3082, 0.2988, 0.3053))\n",
    "        ])\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, slice):\n",
    "            raise NotImplementedError('slicing is not supported')\n",
    "        \n",
    "        row = self.dataFrame.iloc[key]\n",
    "        image = Image.open(row['image']).convert('RGB')\n",
    "        return {\n",
    "          'image': self.transformations(image),\n",
    "          'mask': tensor([row['mask']], dtype=long),\n",
    "          'path': row['image']\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataFrame.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYbnhPp5AolL"
   },
   "source": [
    "# CNN model for face mask detection\n",
    "* The model takes 3 channels(R,G,B) as input\n",
    "* The model gives an output of one of 3 classes \n",
    "* 0 -> without_mask, 1 -> with_mask,2 -> not_a_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qx-LOLixogJb"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The CNN model\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import (Conv2d, CrossEntropyLoss, Linear, MaxPool2d, ReLU,\n",
    "                      Sequential, functional)\n",
    "\n",
    "class FaceMaskDetectorCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceMaskDetectorCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 3)\n",
    "    \n",
    "    def forward(self, x: Tensor):\n",
    "        \"\"\" forward pass\n",
    "        \"\"\"\n",
    "        out = functional.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = functional.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "face_mask_detector_cnn = FaceMaskDetectorCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CD-NueFBWfd"
   },
   "source": [
    "# Layers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3p52rN2Rend",
    "outputId": "e5c65d1b-5f83-4845-c779-e7a3d871f4bc"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print model summary\n",
    "\"\"\"\n",
    "\n",
    "from torchsummary import summary\n",
    "print(summary(face_mask_detector_cnn,input_size=(3,32,32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kt0uRpO-Bn8r"
   },
   "source": [
    "# Split test, validation data\n",
    "* Loads the pickle file that was saved previously\n",
    "* Splits dataset into k-stratified folds that will be used for training and evaluation\n",
    "* Create a DataLoader helper function for automatic batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8T_M5_PkokZd",
    "outputId": "cc84df03-3981-4bec-a6fb-62f316177e39"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some utilities\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import Tensor\n",
    "from torch.nn import (Conv2d, CrossEntropyLoss, Linear, MaxPool2d, ReLU,\n",
    "                      Sequential)\n",
    "from torch.optim import Adam\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cm(cm, classes, normalize=False, title='Visualization of the confusion matrix', cmap=plt.cm.Reds):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def prepare_data(mask_df_path) -> None:\n",
    "        mask_df = pd.read_pickle(mask_df_path)\n",
    "        # print the distribution\n",
    "        print(mask_df['mask'].value_counts())\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "        train_folds = []\n",
    "        validate_folds = []\n",
    "        for train_index, validate_index in skf.split(mask_df, mask_df['mask']):\n",
    "            train_folds.append(MaskDetectionDataset(mask_df.iloc[train_index]))\n",
    "            validate_folds.append(MaskDetectionDataset(mask_df.iloc[validate_index]))\n",
    "        return [\n",
    "            train_folds,\n",
    "            validate_folds,\n",
    "            CrossEntropyLoss()\n",
    "            ]\n",
    "\n",
    "def train_dataloader(train_df) -> DataLoader:\n",
    "    return DataLoader(train_df, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "def val_dataloader(validate_df) -> DataLoader:\n",
    "    return DataLoader(validate_df, batch_size=32, num_workers=0)   \n",
    "\n",
    "train_dfs, validate_dfs, cross_entropy_loss = prepare_data(\"data/dataset/dataset.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKp59vThCMJX"
   },
   "source": [
    "# Training the model\n",
    "* For each batch get the images and its labels\n",
    "* Pass it to the model to get predictions\n",
    "* compare losses with actual, predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DmCWb2_onzJ",
    "outputId": "66c4a847-d84c-4c04-90ab-2b5317e35140"
   },
   "outputs": [],
   "source": [
    "#@title Hyperparameters\n",
    "epochs = 10 #@param {type:\"slider\", min:10, max:100, step:1}\n",
    "learning_rate = 0.001 #@param {type:\"number\"}\n",
    "retrain = False\n",
    "\"\"\"\n",
    "Training Step\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def train_model(train_fold):\n",
    "    optimizer = Adam(face_mask_detector_cnn.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        loss_train = 0.0\n",
    "        for i, data in enumerate(train_dataloader(train_fold), 0):\n",
    "            inputs, labels = data['image'], data['mask']\n",
    "            labels = labels.flatten()\n",
    "            outputs = face_mask_detector_cnn(inputs)\n",
    "            loss = cross_entropy_loss(outputs, labels)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss\n",
    "        print(f'Training Loss (after epoch {epoch}):', loss_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0Por18U-bNd"
   },
   "source": [
    "# Evaluate the model \n",
    "* Run the model to evaluate its accuracy on unseen images using validate dataset\n",
    "* return the metrics for the evaluation done on a specific fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "oAc11Iu-lZWc",
    "outputId": "601f4c2d-57c2-4288-9560-87b4640ae056"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate the model\n",
    "\"\"\"\n",
    "\n",
    "from numpy import vstack\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "def evaluate_model(validate_fold):\n",
    "    predictions, actuals = torch.tensor([]), torch.tensor([])\n",
    "    for i, data in enumerate(val_dataloader(validate_fold)):\n",
    "        inputs, targets = data['image'], data['mask']\n",
    "        targets = targets.flatten()\n",
    "        output = face_mask_detector_cnn(inputs)\n",
    "        output = torch.argmax(output,axis=1)\n",
    "        predictions = torch.cat((predictions, output.flatten()), dim=0)\n",
    "        actuals = torch.cat((actuals, targets), dim=0)\n",
    "\n",
    "    # return metrics\n",
    "    return (confusion_matrix(actuals.numpy(), predictions.numpy()),accuracy_score(actuals, predictions),*precision_recall_fscore_support(actuals.numpy(), predictions.numpy(),average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the k-fold training and evaluation\n",
    "- Iterate over the 10 folds and run the training and evaulate steps at each iteration.\n",
    "- At the end report the average accuracy, precision, recall and f-score and print the confusion matrix corresponding evaluation steps across all 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run k-fold training/validation\n",
    "\"\"\"\n",
    "\n",
    "fold_results = []\n",
    "fold_confusion_matrix = np.zeros((3,3))\n",
    "classes = ['without_mask', 'with_mask', 'not_a_person']\n",
    "\n",
    "for fold_index in range(len(train_dfs)):\n",
    "    train_model(train_dfs[fold_index])\n",
    "    fold_result = evaluate_model(validate_dfs[fold_index])\n",
    "    # conf_mat, acc, pre, recall, f-score\n",
    "    fold_results.append(fold_result[1:-1])\n",
    "    fold_confusion_matrix = np.add(fold_confusion_matrix,fold_result[0])\n",
    "    if fold_index != len(train_dfs)-1:\n",
    "        face_mask_detector_cnn = FaceMaskDetectorCNN()\n",
    "    \n",
    "metrics_df = pd.DataFrame(fold_results, columns=['accuracy', 'precision', 'recall', 'f-score'])\n",
    "print()\n",
    "print(\"Metrics\")\n",
    "print(metrics_df.mean())\n",
    "print()\n",
    "print(\"Across 10-folds\")\n",
    "plot_cm(fold_confusion_matrix, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWmuGuSS-LKw"
   },
   "source": [
    "# Predict the category of an image taken from a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "M5HcysHM4V9x",
    "outputId": "1a57dbde-cc74-47f3-824c-db154440ff51"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predict\n",
    "\"\"\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "class_mapping = {\n",
    "    0: \"without_mask\",\n",
    "    1: \"with_mask\",\n",
    "    2: \"not_a_person\"\n",
    "}\n",
    "\n",
    "def prepare_predict_df():\n",
    "    testDatasetPath = Path('data/dataset/test_data')\n",
    "    testMaskPath = testDatasetPath/'with_mask'\n",
    "    testNonMaskPath = testDatasetPath/'without_mask'\n",
    "    testRandomPath = testDatasetPath/'random'\n",
    "    testDF = pd.DataFrame()\n",
    "\n",
    "    for imgPath in tqdm(list(testMaskPath.iterdir()), desc='with_mask'):\n",
    "        testDF = testDF.append({\n",
    "            'image': str(imgPath),\n",
    "            'mask': 1\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    for imgPath in tqdm(list(testNonMaskPath.iterdir()), desc='without_mask'):\n",
    "        testDF = testDF.append({\n",
    "            'image': str(imgPath),\n",
    "            'mask': 0\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    for imgPath in tqdm(list(testRandomPath.iterdir()), desc='random_images'):\n",
    "        testDF = testDF.append({\n",
    "            'image': str(imgPath),\n",
    "            'mask': 2\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return MaskDetectionDataset(testDF)\n",
    "\n",
    "def predict():\n",
    "  test_df = prepare_predict_df()\n",
    "  rand_sampler = torch.utils.data.RandomSampler(test_df, num_samples=32, replacement=True)\n",
    "  data = iter(DataLoader(test_df, batch_size=32, num_workers=0, sampler=rand_sampler)).next()\n",
    "  inputs,targets = data['image'], data['mask']\n",
    "  output = face_mask_detector_cnn(inputs)\n",
    "  output = torch.argmax(output,axis=1)\n",
    "  rand_ind = random.choice(list(range(0,32)))\n",
    "  print(data['path'][rand_ind])\n",
    "  img = Image.open(data['path'][rand_ind])\n",
    "  plt.imshow(np.asarray(img))\n",
    "  print(\"Actual:\", class_mapping[targets[rand_ind].tolist()[0]])\n",
    "  print(\"Predicted:\",class_mapping[output[rand_ind].tolist()])\n",
    "\n",
    "predict()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "face_mask_detector_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
